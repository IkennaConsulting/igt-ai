


Guardrails are rule-based controls that offer a way of checking and controlling the inputs to and outputs of an AI model. They help enforce organisational safety, security, and compliance policies on AI models interactions. 

Content safety services are model backed services used to provide content moderation, and run content safety classification,  
e.g LLama Guard 3, Azure AI Content Safety, Google Model Armor, and Amazon Bedrock Guardrails.